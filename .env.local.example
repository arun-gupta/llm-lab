# LOCAL ENVIRONMENT VARIABLES
# This file contains sensitive data and should NEVER be committed to git
# Copy this file to .env.local and add your actual API keys

# LLM API Keys (SENSITIVE - Keep these secret!)
# At minimum, add one of these working integrations:
# OpenAI: https://platform.openai.com/api-keys
# Anthropic: https://console.anthropic.com/

OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Coming Soon - Not yet implemented:
# COHERE_API_KEY=your_cohere_api_key_here
# MISTRAL_API_KEY=your_mistral_api_key_here

# Postman API (optional - for generating Postman collections)
# Get your Postman API key from: https://www.postman.com/api/
POSTMAN_API_KEY=your_postman_api_key_here

# Ollama Configuration (optional - for local models)
# Default: http://localhost:11434 (standard Ollama port)
OLLAMA_BASE_URL=http://localhost:11434

# Local development overrides
NEXT_PUBLIC_BASE_URL=http://localhost:3000 

# GitHub Personal Access Token (optional - for MCP server integration)
# Get your token from: https://github.com/settings/tokens (requires 'repo' scope)
GITHUB_TOKEN=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

# GitHub Configuration
GITHUB_REPOS_COUNT=3
